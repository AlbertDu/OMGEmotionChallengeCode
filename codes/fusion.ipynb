{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 250/1972 [00:00<00:00, 2499.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove cbb64e001_14\n",
      "remove 2c09795bb_40\n",
      "remove 9354b482f_9\n",
      "[119 197 563]\n",
      "(1972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1972/1972 [00:01<00:00, 1942.04it/s]\n",
      " 44%|████▍     | 206/470 [00:00<00:00, 2057.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1969, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:00<00:00, 1877.93it/s]\n",
      " 33%|███▎      | 204/617 [00:00<00:00, 1897.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 617/617 [00:00<00:00, 2148.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# load data\n",
    "df_train=pd.read_csv('dataset/train_label.csv')\n",
    "df_test=pd.read_csv('dataset/val_label.csv')\n",
    "\n",
    "# split train/val\n",
    "sp=pd.read_csv('dataset/val_id.csv',header=None).values\n",
    "sp=np.unique(np.array(list(map(lambda x:x[0].split('_')[0],sp))))\n",
    "train_index=[]\n",
    "val_index=[]\n",
    "videos=df_train['video'].values\n",
    "for i,v in enumerate(videos):\n",
    "    if v.split('_')[0] in sp:\n",
    "        val_index.append(i)\n",
    "    else:\n",
    "        train_index.append(i)\n",
    "df_val=df_train.iloc[val_index,:]\n",
    "df_train=df_train.iloc[train_index,:]\n",
    "df_train.head()\n",
    "\n",
    "id_train = df_train[['video','utterance']].values\n",
    "id_train = np.array(list(map(lambda x:x[0].split('_')[0]+'_'+x[1].split('.')[0].split('_')[-1],id_train)))\n",
    "id_val = df_val[['video','utterance']].values\n",
    "id_val = np.array(list(map(lambda x:x[0].split('_')[0]+'_'+x[1].split('.')[0].split('_')[-1],id_val)))\n",
    "id_test = df_test[['video','utterance']].values\n",
    "id_test = np.array(list(map(lambda x:x[0].split('_')[0]+'_'+x[1].split('.')[0].split('_')[-1],id_test)))\n",
    "\n",
    "# remove_list\n",
    "remove_list=['cbb64e001_14','9354b482f_9','2c09795bb_40']\n",
    "remove_index=[]\n",
    "for i,id in enumerate(id_train):\n",
    "    if id in remove_list:\n",
    "        print('remove',id)\n",
    "        remove_index.append(i)\n",
    "remove_index=np.array(remove_index)\n",
    "print(remove_index)\n",
    "print(id_train.shape)\n",
    "id_train=np.delete(id_train, remove_index, axis=0)\n",
    "\n",
    "y_train=df_train[['arousal','valence']].values\n",
    "y_train=np.delete(y_train,remove_index, axis=0)\n",
    "y_val=df_val[['arousal','valence']].values\n",
    "y_test=df_test[['arousal','valence']].values\n",
    "\n",
    "from tqdm import tqdm\n",
    "# read vision feature\n",
    "# train\n",
    "data = h5py.File('/users/seria/TensorFlood/data/seeta_omg/vf-full-train.hdf5', 'r')# vid_vfssdaw_train\n",
    "X_train_vid=[]\n",
    "videos=df_train['video'].values\n",
    "utts=df_train['utterance'].values\n",
    "for i in tqdm(range(len(videos))):\n",
    "    if (videos[i].split('_')[0]+'_'+utts[i].split('.')[0].split('_')[-1]) not in remove_list:\n",
    "        x_temp=data[videos[i]+'_'+utts[i].split('.')[0].split('_')[-1]][:]\n",
    "        X_train_vid.append(x_temp)\n",
    "X_train_vid=np.array(X_train_vid)\n",
    "print(X_train_vid.shape)\n",
    "\n",
    "# val\n",
    "data = h5py.File('/users/seria/TensorFlood/data/seeta_omg/vf-full-val.hdf5', 'r') # vid_vfssdaw_val\n",
    "X_val_vid=[]\n",
    "videos=df_val['video'].values\n",
    "utts=df_val['utterance'].values\n",
    "for i in tqdm(range(len(videos))):\n",
    "    x_temp=data[videos[i]+'_'+utts[i].split('.')[0].split('_')[-1]][:]\n",
    "    X_val_vid.append(x_temp)\n",
    "X_val_vid=np.array(X_val_vid)\n",
    "print(X_val_vid.shape)\n",
    "\n",
    "# test\n",
    "data = h5py.File('/users/seria/TensorFlood/data/seeta_omg/vf-full-test.hdf5', 'r') # vid_vfssdaw_test\n",
    "X_test_vid=[]\n",
    "videos=df_test['video'].values\n",
    "utts=df_test['utterance'].values\n",
    "for i in tqdm(range(len(videos))):\n",
    "    x_temp=data[videos[i]+'_'+utts[i].split('.')[0].split('_')[-1]][:]\n",
    "    X_test_vid.append(x_temp)\n",
    "X_test_vid=np.array(X_test_vid)\n",
    "print(X_test_vid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1969, 512) (470, 512) (617, 512)\n",
      "concated and normed:\n",
      "(1969, 768) (470, 768) (617, 768)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "paths={'aud_CNN':['aud_feature/AudCNN_context0_train_feat.csv',\\\n",
    "                  'aud_feature/AudCNN_context0_val_feat.csv',\\\n",
    "                  'aud_feature/AudCNN_context0_test_feat.csv'],\\\n",
    "      'aud_hand':['../OMG/dataset/aud_train.csv',\\\n",
    "                 '../OMG/dataset/aud_val.csv'],\\\n",
    "      'text_attention':['text_feature/TextAttention_context0_train_feat256.csv',\\\n",
    "                       'text_feature/TextAttention_context0_val_feat256.csv',\\\n",
    "                       'text_feature/TextAttention_context0_test_feat256.csv'],\\\n",
    "      'text_BiGRU':['text_feature/TextGRU_context0_train_feat256.csv',\\\n",
    "                   'text_feature/TextGRU_context0_val_feat256.csv',\\\n",
    "                   'text_feature/TextGRU_context0_test_feat256.csv'],\n",
    "      'vid_CNN':['vid_feature/vidCNN_context0_train_feat.csv',\\\n",
    "                'vid_feature/vidCNN_context0_val_feat.csv',\\\n",
    "                'vid_feature/vidCNN_context0_test_feat.csv']}\n",
    "# 选择非video特征\n",
    "# aud_CNN\n",
    "# aud_hand\n",
    "# text_attention\n",
    "# text_BiGRU\n",
    "feature_list=['aud_hand','text_attention']\n",
    "from sklearn.preprocessing import normalize\n",
    "def combine_features(feature_list, remove_index, id_train, id_val, id_test):\n",
    "    X_train_all=[]\n",
    "    X_val_all=[]\n",
    "    X_test_all=[]\n",
    "    for f in feature_list:\n",
    "        if f=='aud_hand':\n",
    "            df_train=pd.read_csv(paths[f][0])\n",
    "            df_val=pd.read_csv(paths[f][1])\n",
    "            id_train2=df_train.pop('id').values\n",
    "            id_val2=df_val.pop('id').values\n",
    "            df_train.pop('y1');df_val.pop('y1');df_train.pop('y2');df_val.pop('y2')\n",
    "            X_train_temp=df_train.values\n",
    "            X_val_temp=df_val.values\n",
    "            train_index_dict={};val_index_dict={}\n",
    "            X_train_index=[];X_val_index=[];X_test_index=[]\n",
    "            for i,id in enumerate(id_train2):\n",
    "                train_index_dict[id]=i\n",
    "            for i,id in enumerate(id_val2):\n",
    "                val_index_dict[id]=i\n",
    "            for id in id_train:\n",
    "                X_train_index.append(train_index_dict[id])\n",
    "            for id in id_val:\n",
    "                X_val_index.append(train_index_dict[id])\n",
    "            for id in id_test:\n",
    "                X_test_index.append(val_index_dict[id])\n",
    "            X_train_index=np.array(X_train_index);X_val_index=np.array(X_val_index);X_test_index=np.array(X_test_index)\n",
    "            X_test_temp=X_val_temp[X_test_index,:]\n",
    "            X_val_temp=X_train_temp[X_val_index,:]\n",
    "            X_train_temp=X_train_temp[X_train_index,:]\n",
    "        else:\n",
    "            #load data\n",
    "            df_train=pd.read_csv(paths[f][0])\n",
    "            df_val=pd.read_csv(paths[f][1])\n",
    "            df_test=pd.read_csv(paths[f][2])\n",
    "            X_train_temp=df_train.iloc[:,4:].values\n",
    "            X_val_temp=df_val.iloc[:,4:].values\n",
    "            X_test_temp=df_test.iloc[:,4:].values\n",
    "            if f!='vid_CNN':\n",
    "                X_train_temp=np.delete(X_train_temp, remove_index, axis=0)\n",
    "#             if f=='aud_CNN':\n",
    "#                 # l2 norm\n",
    "#                 X_train_temp=normalize(X_train_temp)\n",
    "#                 X_val_temp=normalize(X_val_temp)\n",
    "#                 X_test_temp=normalize(X_test_temp)\n",
    "        X_train_all.append(X_train_temp)\n",
    "        X_val_all.append(X_val_temp)\n",
    "        X_test_all.append(X_test_temp)\n",
    "    X_train_all=np.concatenate(X_train_all,axis=1)\n",
    "    X_val_all=np.concatenate(X_val_all,axis=1)\n",
    "    X_test_all=np.concatenate(X_test_all,axis=1)\n",
    "    \n",
    "    return X_train_all,X_val_all,X_test_all\n",
    "\n",
    "X_train,X_val,X_test=combine_features(feature_list, remove_index, id_train, id_val, id_test)\n",
    "print(X_train.shape,X_val.shape,X_test.shape)\n",
    "# concatenate\n",
    "X_train=np.concatenate((X_train,X_train_vid),axis=1)\n",
    "X_val=np.concatenate((X_val,X_val_vid),axis=1)\n",
    "X_test=np.concatenate((X_test,X_test_vid),axis=1)\n",
    "\n",
    "# X_train=X_train_vid\n",
    "# X_val=X_val_vid\n",
    "# X_test=X_test_vid\n",
    "\n",
    "# # min-max normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# X_all=np.concatenate((X_train,X_val,X_test),axis=0)\n",
    "# scaler.fit(X_all)\n",
    "# X_train=scaler.transform(X_train)\n",
    "# X_val=scaler.transform(X_val)\n",
    "# X_test=scaler.transform(X_test)\n",
    "print('concated and normed:')\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.164842402889 ( 0.382825038176 )\n",
      "{'C': 0.05, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.24674233729 ( 0.392395465634 )\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.260806894109 ( 0.382050362312 )\n",
      "{'C': 0.5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.25824372087 ( 0.339734127662 )\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.248284133357 ( 0.316211714189 )\n",
      "{'C': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.229863039545 ( 0.282727089181 )\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.22467281918 ( 0.2745459775 )\n",
      "{'C': 50, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.220176109595 ( 0.268961711218 )\n",
      "{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.220176109595 ( 0.268961711218 )\n",
      "{'C': 200, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.220176109595 ( 0.268961711218 )\n",
      "best_ccc: 0.260806894109\n",
      "best_param!!!: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "test ccc: 0.213837379197 ( 0.301881825666 )\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "def correct(train_y, pred_val_y):\n",
    "    train_std = np.std(train_y)\n",
    "    val_std = np.std(pred_val_y)\n",
    "    mean = np.mean(pred_val_y)\n",
    "    pred_val_y = np.array(pred_val_y)\n",
    "    pred_val_y = mean + (pred_val_y - mean) * train_std / val_std\n",
    "    return pred_val_y\n",
    "\n",
    "import calccc\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "params = {\n",
    "        'gamma': ['auto'],\n",
    "        'C': [0.01,0.05,0.1,0.5,1,5,10,50,100,200],#\n",
    "        'kernel':['rbf']\n",
    "    }\n",
    "params = list(ParameterGrid(params))\n",
    "best_ccc=0\n",
    "for p in params:\n",
    "    print(p)\n",
    "    clf = svm.SVR(kernel=p['kernel'], C=p['C'], gamma=p['gamma'])#\n",
    "    clf.fit(X_train,y_train[:,0])\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_pred2 = correct(y_train[:,0], y_pred)\n",
    "    ccc,_=calccc.ccc(y_val[:,0],y_pred)\n",
    "    ccc2,_=calccc.ccc(y_val[:,0],y_pred2)\n",
    "    print('ccc:',ccc,'(',ccc2,')')\n",
    "    if ccc>best_ccc:\n",
    "        best_ccc=ccc\n",
    "        best_param=p\n",
    "        best_clf=clf\n",
    "        \n",
    "print('best_ccc:',best_ccc)\n",
    "print('best_param!!!:',best_param)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "y_pred2 = correct(y_train[:,0], y_pred)\n",
    "ccc1,_=calccc.ccc(y_test[:,0],y_pred)\n",
    "ccc2,_=calccc.ccc(y_test[:,0],y_pred2)\n",
    "print('test ccc:',ccc1,'(',ccc2,')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.299731002991 ( 0.512887992407 )\n",
      "{'C': 0.05, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.407437616958 ( 0.516745990482 )\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.433966089496 ( 0.516087912788 )\n",
      "{'C': 0.5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.48143715699 ( 0.523255660701 )\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.479340072111 ( 0.515587173145 )\n",
      "{'C': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.469782546635 ( 0.499084433338 )\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.465777316616 ( 0.493068068177 )\n",
      "{'C': 50, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.463641183104 ( 0.48970169329 )\n",
      "{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.465323122246 ( 0.490386003516 )\n",
      "{'C': 200, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "ccc: 0.465323122246 ( 0.490386003516 )\n",
      "best_ccc: 0.48143715699\n",
      "best_param!!!: {'C': 0.5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "test ccc: 0.239419071175 ( 0.275093753331 )\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'gamma': ['auto'],\n",
    "        'C': [0.01,0.05,0.1,0.5,1,5,10,50,100,200],#\n",
    "        'kernel':['rbf']\n",
    "    }\n",
    "params = list(ParameterGrid(params))\n",
    "best_ccc=0\n",
    "for p in params:\n",
    "    print(p)\n",
    "    clf = svm.SVR(kernel=p['kernel'], C=p['C'], gamma=p['gamma'])#\n",
    "    clf.fit(X_train,y_train[:,1])\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_pred2 = correct(y_train[:,1], y_pred)\n",
    "    ccc,_=calccc.ccc(y_val[:,1],y_pred)\n",
    "    ccc2,_=calccc.ccc(y_val[:,1],y_pred2)\n",
    "    print('ccc:',ccc,'(',ccc2,')')\n",
    "    if ccc>best_ccc:\n",
    "        best_ccc=ccc\n",
    "        best_param=p\n",
    "        best_clf=clf\n",
    "        \n",
    "print('best_ccc:',best_ccc)\n",
    "print('best_param!!!:',best_param)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "y_pred2 = correct(y_train[:,1], y_pred)\n",
    "ccc1,_=calccc.ccc(y_test[:,1],y_pred)\n",
    "ccc2,_=calccc.ccc(y_test[:,1],y_pred2)\n",
    "print('test ccc:',ccc1,'(',ccc2,')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ccc: 0.469285291829 ( 0.477291911208 )\n"
     ]
    }
   ],
   "source": [
    "y_pred_2=y_pred\n",
    "y_pred_fin=0.6*y_pred_1+0.4*y_pred_2\n",
    "y_pred_fin2=correct(y_train[:,1],y_pred_fin)\n",
    "ccc1,_=calccc.ccc(y_test[:,1],y_pred_fin)\n",
    "ccc2,_=calccc.ccc(y_test[:,1],y_pred_fin2)\n",
    "print('test ccc:',ccc1,'(',ccc2,')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "def correct(train_y, pred_val_y):\n",
    "    train_std = np.std(train_y)\n",
    "    val_std = np.std(pred_val_y)\n",
    "    mean = np.mean(pred_val_y)\n",
    "    pred_val_y = np.array(pred_val_y)\n",
    "    pred_val_y = mean + (pred_val_y - mean) * train_std / val_std\n",
    "    return pred_val_y\n",
    "\n",
    "# 自定义ccc评价\n",
    "def metric_ccc(preds,lgbdata):\n",
    "    labels=lgbdata.get_label() \n",
    "    ccc,_=calccc.ccc(labels,preds)\n",
    "    return 'ccc value:',ccc,True\n",
    "\n",
    "# lgb\n",
    "import calccc\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "params = {\n",
    "    'metric': ['metric_ccc'],\n",
    "    'application': ['regression'],\n",
    "    'learning_rate':[0.015],\n",
    "    'feature_fraction': [0.95],\n",
    "    'max_depth': [6],\n",
    "    'num_leaves':[50],\n",
    "    'bagging_fraction': [0.95],\n",
    "    'bagging_freq':[5],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'min_gain_to_split':[0],\n",
    "    'num_iterations':[1000],\n",
    "    'lambda_l1':[0.5],\n",
    "    'lambda_l2':[1.5],\n",
    "    'verbose':[1]\n",
    "}\n",
    "params=list(ParameterGrid(params))\n",
    "lgbtrain=lgb.Dataset(X_train,label=y_train[:,0])\n",
    "lgbeval=lgb.Dataset(X_val,label=y_val[:,0],reference=lgbtrain)\n",
    "best_ccc=0\n",
    "for param in params:\n",
    "    print(param)\n",
    "    clf = lgb.train(param, lgbtrain, valid_sets=lgbeval, num_boost_round=param['num_iterations'], \\\n",
    "                    early_stopping_rounds=50, feval=metric_ccc, verbose_eval=True)\n",
    "    print(clf.best_score)\n",
    "    if clf.best_score['valid_0']['ccc value:']>best_ccc:\n",
    "        best_ccc=clf.best_score['valid_0']['ccc value:']\n",
    "        best_param=param\n",
    "        best_it=clf.best_iteration\n",
    "        best_clf=clf\n",
    "    print('noval best interation: '+str(clf.best_iteration))\n",
    "y_pred = clf.predict(X_val)\n",
    "y_pred2 = correct(y_train[:,0], y_pred)\n",
    "ccc2,_=calccc.ccc(y_val[:,0],y_pred2)\n",
    "print('best validation ccc:',best_ccc,'(',ccc2,')')\n",
    "print('best param:',best_param)\n",
    "print('best iteration:',best_it)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "y_pred2 = correct(y_train[:,0], y_pred)\n",
    "ccc1,_=calccc.ccc(y_test[:,0],y_pred)\n",
    "ccc2,_=calccc.ccc(y_test[:,0],y_pred2)\n",
    "print('test ccc:',ccc1,'(',ccc2,')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
